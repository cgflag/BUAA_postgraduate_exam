# 数理统计模拟题知识点

1.对于总体分布族P_\theta，已知T=T(X)是参数θ的充分统计量, 



又S(X)=G(T(X))，且函数G(T)是**可逆**的,则S(X)也是参数θ的充分统计量。（    ）

它把样本 $X$ 中所有关于参数 $\theta$ 的有用信息都提取出来了，不含任何冗余（关于 $\theta$ 的信息）。

**判定定理（分解定理 Factorization Theorem）**：

如果似然函数 $f(x;\theta)$ 可以分解为：



$$f(x;\theta) = g(T(x), \theta) \cdot h(x)$$



其中 $g$ 只依赖于统计量和参数，$h$ 与参数无关，那么 $T(X)$ 就是充分统计量。

如果一个统计量 $T$ 满足：只要 $E[g(T)] = 0$ 对所有 $\theta$ 都成立，就能推出 $g(T) = 0$ 几乎处处成立，那它就是完备的。

（2）

$$E[\hat{\theta}^2] = D(\hat{\theta}) + (E[\hat{\theta}])^2$$

题目又给出 $D(\hat{\theta}) > 0$，所以：



$$E[\hat{\theta}^2] = \theta^2 + \text{一个正数} > \theta^2$$

**结论：** $E[\hat{\theta}^2] \neq \theta^2$，实际上 $\hat{\theta}^2$ 是 $\theta^2$ 的**高估**（即正偏估计）。

（3）$$P(\theta | x) \propto P(x | \theta) \cdot P(\theta)$$

即：**后验分布 $\propto$ 似然函数 $\times$ 先验分布**

**数据的压制：** 随着样本量 $n \to \infty$，似然函数 $P(x | \theta)$ 在后验分布中所占的权重会迅速增加。因为似然函数是 $n$ 个独立同分布样本概率的乘积，它包含的信息量会呈指数级增长。

（4）

对于一个 $p$ 维随机向量 ${X} = (X_1, X_2, \dots, X_p)^T$，判断它是否服从多元正态分布 $\mathcal{N}_p(\boldsymbol{\mu}, \boldsymbol{\Sigma})$，通常有三个等价层面：

- **定义法（线性组合）：** 也就是本题所说的，${X}$ 的**任何**线性组合 ${c}^T{X} = c_1X_1 + \dots + c_pX_p$ 都服从一维正态分布。
- **密度函数法：** 存在均值向量 $\boldsymbol{\mu}$ 和协方差矩阵 $\boldsymbol{\Sigma}$，其概率密度函数符合那个复杂的指数形式（前提是 $\boldsymbol{\Sigma}$ 正定）。
- **特征函数法：** 其特征函数具有 $\exp\{i\mathbf{t}^T\boldsymbol{\mu} - \frac{1}{2}\mathbf{t}^T\boldsymbol{\Sigma}\mathbf{t}\}$ 的形式。

但不代表每个边缘分布都正态

对于多元正态，若协方差 $\text{Cov}(X_i, X_j) = 0$，则它们一定独立。（这是正态分布特有的“特权”）。

若 ${X} \sim \mathcal{N}_p(\boldsymbol{\mu}, \boldsymbol{\Sigma})$，则 $\mathbf{A}{X} + \mathbf{b}$ 依然服从多元正态分布，均值变为 $\mathbf{A}\boldsymbol{\mu} + \mathbf{b}$，协方差变为 $\mathbf{A}\boldsymbol{\Sigma}\mathbf{A}^T$

特征函数$\exp\{i \times \text{均值项} - \frac{1}{2} \times \text{方差项}\}$

## 填空题

（1）这道填空题的答案是：**$T = (X_{(1)}, X_{(n)})$**，即样本的**最小观测值和最大观测值组成的向量**。

（注：在某些评分标准下，写出具体形式如 $(\min X_i, \max X_i)$ 也是对的。）

------

### 1. 核心知识点：费舍尔-奈曼分解定理 (Factorization Theorem)

这是解决所有“求充分统计量”问题的万能钥匙。要找充分统计量，必须先把似然函数 $L(\theta)$ 写出来，并尝试分解为：



$$L(\theta) = g(T(x), \theta) \cdot h(x)$$



如果能成功分解，那么 $T(x)$ 就是充分统计量。

### 2. 深度解析：为什么均匀分布比较“特殊”？

均匀分布的似然函数最容易让学生丢分，因为它的参数 $\theta$ 隐藏在**定义域（指示函数）**里。

第一步：写出单个样本的密度函数



$$f(x;\theta) = \frac{1}{2\theta - \theta} I_{\{\theta \le x \le 2\theta\}} = \frac{1}{\theta} I_{\{\theta \le x \le 2\theta\}}$$



这里的 $I$ 是指示函数，表示只有当 $x$ 在 $[\theta, 2\theta]$ 之间时，概率才不为 0。

第二步：写出样本联合密度（似然函数）



$$L(\theta) = \prod_{i=1}^{n} \frac{1}{\theta} I_{\{\theta \le x_i \le 2\theta\}} = \frac{1}{\theta^n} \prod_{i=1}^{n} I_{\{\theta \le x_i \le 2\theta\}}$$

第三步：转化指示函数（应试核心技巧）

所有 $x_i$ 都在 $[\theta, 2\theta]$ 之间，等价于：最小的 $x_i$ 大于 $\theta$ 且 最大的 $x_i$ 小于 $2\theta$。

所以：



$$L(\theta) = \frac{1}{\theta^n} I_{\{\theta \le X_{(1)}\}} \cdot I_{\{X_{(n)} \le 2\theta\}}$$



（其中 $X_{(1)} = \min(x_i)$，$X_{(n)} = \max(x_i)$）

第四步：识别 $g(T, \theta)$

观察上式，整个式子都包含参数 $\theta$，且只通过 $X_{(1)}$ 和 $X_{(n)}$ 与样本发生联系。

令 $T = (X_{(1)}, X_{(n)})$，则 $L(\theta)$ 可以完全表示为 $g(T, \theta)$ 的形式（此时 $h(x)=1$）。



| **总体分布范围**            | **充分统计量 T**     |
| --------------------------- | -------------------- |
| $U(0, \theta)$              | $X_{(n)}$ (最大值)   |
| $U(\theta, \theta+1)$       | $(X_{(1)}, X_{(n)})$ |
| $U(-\theta, \theta)$        | $T = \max |X_i|$     |
| **$U(\theta_1, \theta_2)$** | $(X_{(1)}, X_{(n)})$ |

（2）

### 核心知识点：MLE 的“三步走”套路

无论分布看起来多怪异，求 MLE 的步骤永远是固定的。在考场上，你只需要在草稿纸上机械化执行以下操作：

1. **构造似然函数 $L(\theta)$：** 把所有样本的密度函数乘起来。
2. **取对数 $\ln L(\theta)$：** 目的是把连乘变连加，方便求导。
3. **求导定最值：** 对 $\theta$ 求导，令其为 0（即解似然方程）。（有时可能不能取0）

（3）

$$P(\theta | X) = \frac{P(X | \theta) P(\theta)}{\sum P(X | \theta_i) P(\theta_i)}$$

第一步：先验概率

题目给定 $\theta$ 的取值集合为 $\Theta = \{ \frac{1}{4}, \frac{1}{2}, \frac{3}{4} \}，及各自概率$

第二步：计算似然值（当 $X=2$ 时）

根据分布列 $P(X=x) = \theta(1-\theta)^x$，代入 $x=2$：

1. 当 $\theta = \frac{1}{4}$ 时，$P(X=2 | \theta = \frac{1}{4}) = \frac{1}{4}(1-\frac{1}{4})^2 = \frac{1}{4} \cdot \frac{9}{16} = \frac{9}{64}$
2. 当 $\theta = \frac{1}{2}$ 时，$P(X=2 | \theta = \frac{1}{2}) = \frac{1}{2}(1-\frac{1}{2})^2 = \frac{1}{2} \cdot \frac{1}{4} = \frac{1}{8} = \frac{8}{64}$
3. 当 $\theta = \frac{3}{4}$ 时，$P(X=2 | \theta = \frac{3}{4}) = \frac{3}{4}(1-\frac{3}{4})^2 = \frac{3}{4} \cdot \frac{1}{16} = \frac{3}{64}$

第三步：计算后验概率

后验概率正比于“先验 $\times$ 似然”。因为先验概率都是 $1/3$，在计算相对比例时可以抵消。 后验分母（全概率）：$\frac{1}{3} \cdot (\frac{9}{64} + \frac{8}{64} + \frac{3}{64}) = \frac{1}{3} \cdot \frac{20}{64} = \frac{20}{192}$。

后验概率：

$P(\theta = \frac{1}{4} | X=2) = \frac{9/192}{20/192} = \frac{9}{20}$

$P(\theta = \frac{1}{2} | X=2) = \frac{8/192}{20/192} = \frac{8}{20}$

$P(\theta = \frac{3}{4} | X=2) = \frac{3/192}{20/192} = \frac{3}{20}$

第四步：计算后验期望 $E(\theta | X=2)$



$$E = \sum \theta_i \cdot P(\theta_i | X=2)$$

$$E = \left( \frac{1}{4} \cdot \frac{9}{20} \right) + \left( \frac{1}{2} \cdot \frac{8}{20} \right) + \left( \frac{3}{4} \cdot \frac{3}{20} \right)$$

$$E = \frac{9}{80} + \frac{16}{80} + \frac{9}{80} = \frac{34}{80} = \frac{17}{40} = 0.425$$

**θ**先验 **P(θ)**似然 **P(X∣θ)**先验**×**似然后验 **P(θ∣X)**

整理为表格

（4）

符号秩和检验

**第一步：计算差值 $d_i = X_i - Y_i$**

列表

**第二步：取绝对值并排秩（Rank）** 先不管正负号，对 $|d_i|$ 从小到大排秩。如果数值相同（结，ties），取秩的平均值。

**第三步：计算 $W^+$（正秩和）** 把所有正差值对应的秩相加：

$$W^+ = 3.5 (\text{对应 } d=2) + 7 (\text{对应 } d=6) + 8 (\text{对应 } d=10)$$

$$W^+ = 3.5 + 7 + 8 = 18.5$$

**差值为 0：** 如果某个用户给两个品牌打分一样（$d_i=0$），通常的做法是**直接剔除**该样本，并相应减小样本量 $n$。

**符号弄反：** 算出差值后，一定要标清正负号。

**相同秩（Ties）：** 记得取平均秩，比如两个第二名，秩就是 $(2+3)/2 = 2.5$。

验算：

算完 $W^+$ 最好再算一遍 $W^-$，用 $W^+ + W^- = n(n+1)/2$ 校验一下。如果对不上，说明你秩排错了。

## 简答

（1）

第一步：找充分完备统计量。其函数无偏UMVUE

通常先算单个样本的信息量 $I(\mu)$，再利用性质 $I_n(\mu) = n \cdot I(\mu)$。

2. 样本所包含的 Fisher 信息量 $I_n(\mu)$

**知识点解析：** Fisher 信息量衡量的是样本携带的关于参数信息的多寡。

$$I(\mu) = E \left[ \left( \frac{\partial \ln f(x;\mu)}{\partial \mu} \right)^2 \right] = -E \left[ \frac{\partial^2 \ln f(x;\mu)}{\partial \mu^2} \right]$$

**具体推导（以 $N(\mu, \sigma^2)$ 为例）：**

1. $\ln f(x;\mu) = -\ln(\sqrt{2\pi}\sigma) - \frac{(x-\mu)^2}{2\sigma^2}$
2. 对 $\mu$ 求一阶导：$\frac{\partial \ln f}{\partial \mu} = \frac{x-\mu}{\sigma^2}$
3. 对 $\mu$ 求二阶导：$\frac{\partial^2 \ln f}{\partial \mu^2} = -\frac{1}{\sigma^2}$
4. 取负号并求期望：$I(\mu) = -E[-\frac{1}{\sigma^2}] = \frac{1}{\sigma^2}$

**结论：** 样本（$n$个）的总信息量 $I_n(\mu) = \frac{n}{\sigma^2}$。

3. 证明 $\bar{X}$ 是参数 $\mu$ 的有效估计

第一步：计算 C-R 下界。



$$CRLB = \frac{1}{I_n(\mu)} = \frac{1}{n/\sigma^2} = \frac{\sigma^2}{n}$$

第二步：计算估计量的实际方差。

对于 $\bar{X}$，我们已知其方差 $D(\bar{X}) = \frac{\sigma^2}{n}$。

第三步：比较。

因为 $D(\bar{X}) = CRLB$，即估计量的方差已经达到了理论上的最小值。

**结论：** $\bar{X}$ 是 $\mu$ 的**有效估计**（也称为充分有效估计）。

求 Fisher 信息量时，用**二阶导数的期望**通常比用一阶导数的平方期望要简单得多，不容易算错。



（2）

①似然比检验

$\lambda = \frac{\sup_{\Theta_0} L(\sigma^2)}{\sup_{\Theta} L(\sigma^2)}$。

第一步：写出似然函数

$L(\sigma^2) = (2\pi\sigma^2)^{-n/2} \exp\left(-\frac{\sum X_i^2}{2\sigma^2}\right)$。

第二步：求**全空间**最大值

通过 MLE 可得，全空间下的极大似然估计为 $\hat{\sigma}^2 = \frac{1}{n}\sum X_i^2$。

**第三步：求原假设空间 $\sigma^2 \le \sigma_0^2$ 下的最大值**。参数$\sigma^2$

- 若 $\hat{\sigma}^2 \le \sigma_0^2$，则最大值在 $\hat{\sigma}^2$ 处取得。
- 若 $\hat{\sigma}^2 > \sigma_0^2$，由于 $L(\sigma^2)$ 在 $\hat{\sigma}^2$ 左侧单调递增，故最大值在边界 $\sigma_0^2$ 处取得。

第四步：确定拒绝域

似然比检验等价于：当 $\sum X_i^2$ 很大时拒绝 $H_0$。

构造统计量：$\chi^2 = \frac{\sum X_i^2}{\sigma_0^2} \sim \chi^2(n)$（在 $\sigma^2 = \sigma_0^2$ 时）。

拒绝域为：$W = \{ \frac{\sum X_i^2}{\sigma_0^2} > \chi_{1-\alpha}^2(n) \}$，其中 $\chi_{1-\alpha}^2(n)$ 是 $\chi^2$ 分布的上 $\alpha$ 分位数。

(3)

求 $Y = 2X_1 - X_2 + 3X_3$ 的分布



设线性组合系数向量 $\mathbf{c} = (2, -1, 3)^T$，则 $D[Y] = \mathbf{c}^T \Sigma \mathbf{c}$

② 求 $a$ 与 $b$ 使 $X_3$ 与 $X_3 + aX_1 + bX_2$ 独立

**知识点：** 对于多元正态分布，**独立性等价于协方差为 0**。

核心知识点

1. **多元正态性质：** 若 $\mathbf{X} \sim N_p(\boldsymbol{\mu}, \Sigma)$，则对于任何 $q \times p$ 矩阵 $\mathbf{A}$，有 $\mathbf{AX} \sim N_q(\mathbf{A}\boldsymbol{\mu}, \mathbf{A}\Sigma\mathbf{A}^T)$。第一问其实就是 $\mathbf{A}$ 为行向量的情况。
2. **不相关性 $\iff$ 独立性：** 这是正态分布的“金牌性质”。对于一般分布，不相关不一定独立；但对于正态分布，$\text{Cov}(Y_1, Y_2) = 0$ 是 $Y_1, Y_2$ 独立的充要条件。
3. **协方差的双线性性质：** $\text{Cov}(\sum a_i X_i, \sum b_j Y_j) = \sum \sum a_i b_j \text{Cov}(X_i, Y_j)$。这是处理第二问这种组合独立性问题的基础。



延申

条件分布

分块

套用条件均值公式：$$E(X_1 | X_3) = \mu_1 + \Sigma_{13} \Sigma_{33}^{-1} (X_3 - \mu_3)$$

$$D(X_1 | X_3) = \Sigma_{11} - \Sigma_{13} \Sigma_{33}^{-1} \Sigma_{31}$$

#### 第一步：重新分块

我们要把 $\mathbf{X}$ 分成两部分：待求部分 $\mathbf{X}_A = (X_1, X_2)^T$ 和已知条件部分 $\mathbf{X}_B = (X_3)$。

- 均值分块：

  $\boldsymbol{\mu}_A = \begin{pmatrix} 2 \\ -3 \end{pmatrix}, \quad \boldsymbol{\mu}_B = (1)$

- 协方差矩阵分块：

  根据原矩阵 $\Sigma = \begin{pmatrix} 1 & 1 & 1 \\ 1 & 2 & 2 \\ 1 & 2 & 3 \end{pmatrix}$：

  - $\Sigma_{AA} = \begin{pmatrix} 1 & 1 \\ 1 & 2 \end{pmatrix}$ （$X_1, X_2$ 的自协方差）
  - $\Sigma_{BB} = (3)$ （$X_3$ 的方差）
  - $\Sigma_{AB} = \begin{pmatrix} 1 \\ 2 \end{pmatrix}, \quad \Sigma_{BA} = \begin{pmatrix} 1 & 2 \end{pmatrix}$ （$X_1, X_2$ 与 $X_3$ 的协方差）

#### 第二步：套用相同的公式（向量版）

$$E(\mathbf{X}_A | \mathbf{X}_B) = \boldsymbol{\mu}_A + \Sigma_{AB} \Sigma_{BB}^{-1} (\mathbf{X}_B - \boldsymbol{\mu}_B)$$

#### 第三步：代入计算

1. **偏移量：** $(X_3 - \mu_3) = (1 - 1) = 0$。
2. **修正项：** $\Sigma_{AB} \Sigma_{BB}^{-1} \cdot 0 = \mathbf{0}$。
3. **结果：** $E(X_1, X_2 | X_3 = 1) = \begin{pmatrix} 2 \\ -3 \end{pmatrix} + \begin{pmatrix} 0 \\ 0 \end{pmatrix} = \begin{pmatrix} 2 \\ -3 \end{pmatrix}$。

> 老师点评： 这题虽然算出来结果正好等于初始均值（因为观测值 $X_3$ 恰好等于其均值），但如果 $X_3 = 2$，你的计算过程就是：
>
> $E = \begin{pmatrix} 2 \\ -3 \end{pmatrix} + \begin{pmatrix} 1 \\ 2 \end{pmatrix} \cdot \frac{1}{3} \cdot (2 - 1) = \begin{pmatrix} 2 + 1/3 \\ -3 + 2/3 \end{pmatrix} = \begin{pmatrix} 7/3 \\ -7/3 \end{pmatrix}$。

------

### 3. 深度考点：条件方差矩阵 $D(X_1, X_2 | X_3)$

考试如果考了条件均值，接下来很可能连带考条件方差。记住，条件方差是不随观测值改变的：



$$D(\mathbf{X}_A | \mathbf{X}_B) = \Sigma_{AA} - \Sigma_{AB} \Sigma_{BB}^{-1} \Sigma_{BA}$$



在这个例子中：



$$D = \begin{pmatrix} 1 & 1 \\ 1 & 2 \end{pmatrix} - \begin{pmatrix} 1 \\ 2 \end{pmatrix} \cdot \frac{1}{3} \cdot \begin{pmatrix} 1 & 2 \end{pmatrix} = \begin{pmatrix} 1 & 1 \\ 1 & 2 \end{pmatrix} - \begin{pmatrix} 1/3 & 2/3 \\ 2/3 & 4/3 \end{pmatrix} = \begin{pmatrix} 2/3 & 1/3 \\ 1/3 & 2/3 \end{pmatrix}$$

------

### 老师给你的应试总结：

- **均值公式：** 关键在“偏移修正”，$X_B$ 离均值越远，对 $X_A$ 的修正越大。
- **方差公式：** 关键在“信息减少”，$\Sigma_{AA}$ 是原始不确定性，减去的那部分是因为知道 $X_B$ 后消除的不确定性。